{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"360\" />\n",
    "\n",
    "# Model evaluation - Recall Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. [Problem Statement](#section1)<br>\n",
    "2. [Data Loading and Description](#section2)<br>\n",
    "3. [Exploratory Data Analysis](#section3)<br>\n",
    "4. [Random Forest Classifier](#section4)<br>\n",
    "5. [Model evaluation](#section5)<br>\n",
    "    - 5.1 [Model evaluation using accuracy score](#section501)<br>\n",
    "    - 5.2 [Model Evaluation using confusion matrix](#section502)<br>\n",
    "    - 5.3 [Model evaluation using precision score](#section503)<br>\n",
    "    - 5.4 [Model evaluation using recall score](#section504)<br>\n",
    "    - 5.5 [Model evaluation using f1_score](#section505)<br>\n",
    "    - 5.6 [Model evaluation using ROC_AUC curve](#section506)<br>\n",
    "    - 5.7 [Choosing better model using recall score](#section507)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "Given the __credit card transaction__ dataset, make a model to predict transactions are fradulent or not using random forest algorithm. Evaluate the model using possible __model evaluation techniques__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains _transactions made by credit cards in September 2013 by european cardholders_. This dataset presents transactions that occurred in two days, where we have __38 frauds__ out of __10000 transactions__. The dataset is _highly unbalanced_, the positive class (frauds) account for __0.0038%__ of all transactions.\n",
    "\n",
    "It contains only __numerical input variables__ which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are '__Time__' and '__Amount__'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature '__Class__' is the response variable and it takes value __1__ in case of __fraud__ and __0 otherwise__. \n",
    "\n",
    "- __False Positive__ are the cases where the we would predict that the transaction would be fraudulent whereas actually it wont be.\n",
    "- __False Negative__ would be the case when we would predict that transaction is not fradulent but actually it would be fraudulent.\n",
    "\n",
    "Now, there's a need to reduce both false positive and false negative, but simultaneous reduction of these two is not possible. So, we need to trade off one of them. Thinking from the perspective of the company, __minimising False negative__ cases is of prime concern as _letting go fradulent transaction would lead to monetary loss and customer dissatisfaction_ whereas classifying non-fradulent transactions as fraud would just involve transaction validation by contacting the customer via call or email, and it wouldnt cost much to the company as compared to the case where there can be huge monetary loss due to fraudulent transaction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing Packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "hj8UmUJeU8tO",
    "outputId": "f18d948e-e1f4-4f7f-c39d-7fe2b00669ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-2/master/CaseStudy/credit_fraud.csv')\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "r-NdDTW3ylAu",
    "outputId": "10d13550-82db-406c-f6bb-ad0dc2474be1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzrXmgB6yrnK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the descriptive statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5966.033400</td>\n",
       "      <td>4473.403739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2072.750000</td>\n",
       "      <td>4563.500000</td>\n",
       "      <td>10233.250000</td>\n",
       "      <td>15012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.241862</td>\n",
       "      <td>1.521679</td>\n",
       "      <td>-27.670569</td>\n",
       "      <td>-1.013283</td>\n",
       "      <td>-0.372799</td>\n",
       "      <td>1.150864</td>\n",
       "      <td>1.960497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.281949</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>-34.607649</td>\n",
       "      <td>-0.208342</td>\n",
       "      <td>0.288524</td>\n",
       "      <td>0.901879</td>\n",
       "      <td>8.636214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.906270</td>\n",
       "      <td>1.159154</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>0.412799</td>\n",
       "      <td>0.944361</td>\n",
       "      <td>1.602903</td>\n",
       "      <td>4.101716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.264148</td>\n",
       "      <td>1.441235</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-0.614424</td>\n",
       "      <td>0.219861</td>\n",
       "      <td>1.125666</td>\n",
       "      <td>10.463020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.046398</td>\n",
       "      <td>1.182935</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-0.643390</td>\n",
       "      <td>-0.152769</td>\n",
       "      <td>0.371081</td>\n",
       "      <td>34.099309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>1.307311</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-0.629934</td>\n",
       "      <td>-0.152566</td>\n",
       "      <td>0.505357</td>\n",
       "      <td>21.393069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.071689</td>\n",
       "      <td>1.077430</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-0.542336</td>\n",
       "      <td>-0.055585</td>\n",
       "      <td>0.476280</td>\n",
       "      <td>34.303177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.064778</td>\n",
       "      <td>1.259064</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-0.190747</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>5.060381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.802224</td>\n",
       "      <td>1.155198</td>\n",
       "      <td>-6.329801</td>\n",
       "      <td>0.070868</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>1.506299</td>\n",
       "      <td>10.392889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.222998</td>\n",
       "      <td>1.093548</td>\n",
       "      <td>-13.193415</td>\n",
       "      <td>-0.688422</td>\n",
       "      <td>-0.340720</td>\n",
       "      <td>0.174295</td>\n",
       "      <td>12.259949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.766066</td>\n",
       "      <td>1.168600</td>\n",
       "      <td>-2.595325</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.746752</td>\n",
       "      <td>1.576540</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-1.272513</td>\n",
       "      <td>1.527660</td>\n",
       "      <td>-17.769143</td>\n",
       "      <td>-2.368115</td>\n",
       "      <td>-1.621015</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>3.774837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.851410</td>\n",
       "      <td>1.213055</td>\n",
       "      <td>-3.389510</td>\n",
       "      <td>-0.017984</td>\n",
       "      <td>0.919134</td>\n",
       "      <td>1.768889</td>\n",
       "      <td>4.465413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.700597</td>\n",
       "      <td>1.239290</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.899792</td>\n",
       "      <td>1.499211</td>\n",
       "      <td>5.748734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.129634</td>\n",
       "      <td>0.975573</td>\n",
       "      <td>-4.152532</td>\n",
       "      <td>-0.709531</td>\n",
       "      <td>-0.010078</td>\n",
       "      <td>0.533501</td>\n",
       "      <td>3.635042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.007757</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>-12.227189</td>\n",
       "      <td>-0.495536</td>\n",
       "      <td>0.066086</td>\n",
       "      <td>0.547399</td>\n",
       "      <td>4.087802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.318991</td>\n",
       "      <td>0.966392</td>\n",
       "      <td>-18.587366</td>\n",
       "      <td>-0.180029</td>\n",
       "      <td>0.297423</td>\n",
       "      <td>0.782865</td>\n",
       "      <td>7.893393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.016074</td>\n",
       "      <td>0.794259</td>\n",
       "      <td>-6.920762</td>\n",
       "      <td>-0.450302</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.459390</td>\n",
       "      <td>4.115560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.070415</td>\n",
       "      <td>0.808373</td>\n",
       "      <td>-4.932733</td>\n",
       "      <td>-0.552134</td>\n",
       "      <td>-0.077208</td>\n",
       "      <td>0.442908</td>\n",
       "      <td>4.555359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.589994</td>\n",
       "      <td>-13.276034</td>\n",
       "      <td>-0.149981</td>\n",
       "      <td>-0.021415</td>\n",
       "      <td>0.156534</td>\n",
       "      <td>8.012574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.051990</td>\n",
       "      <td>0.913811</td>\n",
       "      <td>-11.468435</td>\n",
       "      <td>-0.268120</td>\n",
       "      <td>-0.123273</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>22.588989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.152671</td>\n",
       "      <td>0.631083</td>\n",
       "      <td>-8.527145</td>\n",
       "      <td>-0.549638</td>\n",
       "      <td>-0.136746</td>\n",
       "      <td>0.247490</td>\n",
       "      <td>4.534454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.033268</td>\n",
       "      <td>0.487814</td>\n",
       "      <td>-15.144340</td>\n",
       "      <td>-0.174120</td>\n",
       "      <td>-0.045794</td>\n",
       "      <td>0.081665</td>\n",
       "      <td>13.876221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.594430</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-0.327817</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.410877</td>\n",
       "      <td>3.200201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.428171</td>\n",
       "      <td>-2.577363</td>\n",
       "      <td>-0.158137</td>\n",
       "      <td>0.121001</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>5.525093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.562793</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-0.327974</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.476394</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.410868</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-0.084489</td>\n",
       "      <td>-0.004568</td>\n",
       "      <td>0.120811</td>\n",
       "      <td>8.254376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.266247</td>\n",
       "      <td>-3.509250</td>\n",
       "      <td>-0.015753</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>0.077182</td>\n",
       "      <td>4.860769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>63.030188</td>\n",
       "      <td>184.486158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>50.960000</td>\n",
       "      <td>7712.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.061530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         mean          std        min          25%  \\\n",
       "Time    10000.0  5966.033400  4473.403739   0.000000  2072.750000   \n",
       "V1      10000.0    -0.241862     1.521679 -27.670569    -1.013283   \n",
       "V2      10000.0     0.281949     1.308139 -34.607649    -0.208342   \n",
       "V3      10000.0     0.906270     1.159154 -15.496222     0.412799   \n",
       "V4      10000.0     0.264148     1.441235  -4.657545    -0.614424   \n",
       "V5      10000.0    -0.046398     1.182935 -32.092129    -0.643390   \n",
       "V6      10000.0     0.133108     1.307311 -23.496714    -0.629934   \n",
       "V7      10000.0    -0.071689     1.077430 -26.548144    -0.542336   \n",
       "V8      10000.0    -0.064778     1.259064 -23.632502    -0.190747   \n",
       "V9      10000.0     0.802224     1.155198  -6.329801     0.070868   \n",
       "V10     10000.0    -0.222998     1.093548 -13.193415    -0.688422   \n",
       "V11     10000.0     0.766066     1.168600  -2.595325    -0.063689   \n",
       "V12     10000.0    -1.272513     1.527660 -17.769143    -2.368115   \n",
       "V13     10000.0     0.851410     1.213055  -3.389510    -0.017984   \n",
       "V14     10000.0     0.700597     1.239290 -19.214325     0.080400   \n",
       "V15     10000.0    -0.129634     0.975573  -4.152532    -0.709531   \n",
       "V16     10000.0    -0.007757     0.882057 -12.227189    -0.495536   \n",
       "V17     10000.0     0.318991     0.966392 -18.587366    -0.180029   \n",
       "V18     10000.0    -0.016074     0.794259  -6.920762    -0.450302   \n",
       "V19     10000.0    -0.070415     0.808373  -4.932733    -0.552134   \n",
       "V20     10000.0     0.027511     0.589994 -13.276034    -0.149981   \n",
       "V21     10000.0    -0.051990     0.913811 -11.468435    -0.268120   \n",
       "V22     10000.0    -0.152671     0.631083  -8.527145    -0.549638   \n",
       "V23     10000.0    -0.033268     0.487814 -15.144340    -0.174120   \n",
       "V24     10000.0     0.021335     0.594430  -2.512377    -0.327817   \n",
       "V25     10000.0     0.087146     0.428171  -2.577363    -0.158137   \n",
       "V26     10000.0     0.108140     0.562793  -1.338556    -0.327974   \n",
       "V27     10000.0     0.005518     0.410868  -7.976100    -0.084489   \n",
       "V28     10000.0     0.002915     0.266247  -3.509250    -0.015753   \n",
       "Amount  10000.0    63.030188   184.486158   0.000000     5.000000   \n",
       "Class   10000.0     0.003800     0.061530   0.000000     0.000000   \n",
       "\n",
       "                50%           75%           max  \n",
       "Time    4563.500000  10233.250000  15012.000000  \n",
       "V1        -0.372799      1.150864      1.960497  \n",
       "V2         0.288524      0.901879      8.636214  \n",
       "V3         0.944361      1.602903      4.101716  \n",
       "V4         0.219861      1.125666     10.463020  \n",
       "V5        -0.152769      0.371081     34.099309  \n",
       "V6        -0.152566      0.505357     21.393069  \n",
       "V7        -0.055585      0.476280     34.303177  \n",
       "V8         0.012865      0.274533      5.060381  \n",
       "V9         0.805275      1.506299     10.392889  \n",
       "V10       -0.340720      0.174295     12.259949  \n",
       "V11        0.746752      1.576540     12.018913  \n",
       "V12       -1.621015      0.082667      3.774837  \n",
       "V13        0.919134      1.768889      4.465413  \n",
       "V14        0.899792      1.499211      5.748734  \n",
       "V15       -0.010078      0.533501      3.635042  \n",
       "V16        0.066086      0.547399      4.087802  \n",
       "V17        0.297423      0.782865      7.893393  \n",
       "V18        0.025225      0.459390      4.115560  \n",
       "V19       -0.077208      0.442908      4.555359  \n",
       "V20       -0.021415      0.156534      8.012574  \n",
       "V21       -0.123273      0.032707     22.588989  \n",
       "V22       -0.136746      0.247490      4.534454  \n",
       "V23       -0.045794      0.081665     13.876221  \n",
       "V24        0.079976      0.410877      3.200201  \n",
       "V25        0.121001      0.359058      5.525093  \n",
       "V26        0.042865      0.476394      3.517346  \n",
       "V27       -0.004568      0.120811      8.254376  \n",
       "V28        0.015897      0.077182      4.860769  \n",
       "Amount    15.950000     50.960000   7712.430000  \n",
       "Class      0.000000      0.000000      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the info of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      "Time      10000 non-null int64\n",
      "V1        10000 non-null float64\n",
      "V2        10000 non-null float64\n",
      "V3        10000 non-null float64\n",
      "V4        10000 non-null float64\n",
      "V5        10000 non-null float64\n",
      "V6        10000 non-null float64\n",
      "V7        10000 non-null float64\n",
      "V8        10000 non-null float64\n",
      "V9        10000 non-null float64\n",
      "V10       10000 non-null float64\n",
      "V11       10000 non-null float64\n",
      "V12       10000 non-null float64\n",
      "V13       10000 non-null float64\n",
      "V14       10000 non-null float64\n",
      "V15       10000 non-null float64\n",
      "V16       10000 non-null float64\n",
      "V17       10000 non-null float64\n",
      "V18       10000 non-null float64\n",
      "V19       10000 non-null float64\n",
      "V20       10000 non-null float64\n",
      "V21       10000 non-null float64\n",
      "V22       10000 non-null float64\n",
      "V23       10000 non-null float64\n",
      "V24       10000 non-null float64\n",
      "V25       10000 non-null float64\n",
      "V26       10000 non-null float64\n",
      "V27       10000 non-null float64\n",
      "V28       10000 non-null float64\n",
      "Amount    10000 non-null float64\n",
      "Class     10000 non-null int64\n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "fraud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the missing values present in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using RobustScaler, scale the variables 'Time' and 'Amount'.\n",
    "- Please refer to the link of RobustScalar - http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "fraud['scaled_amount'] = rob_scaler.fit_transform(fraud['Amount'].values.reshape(-1,1))\n",
    "fraud['scaled_time'] = rob_scaler.fit_transform(fraud['Time'].values.reshape(-1,1))\n",
    "\n",
    "fraud.drop(['Time','Amount'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>2.908399</td>\n",
       "      <td>-0.559218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.288512</td>\n",
       "      <td>-0.559218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>7.891862</td>\n",
       "      <td>-0.559096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>2.340078</td>\n",
       "      <td>-0.559096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.175805</td>\n",
       "      <td>-0.558973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
       "0 -0.189115  0.133558 -0.021053      0       2.908399    -0.559218  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.288512    -0.559218  \n",
       "2 -0.139097 -0.055353 -0.059752      0       7.891862    -0.559096  \n",
       "3 -0.221929  0.062723  0.061458      0       2.340078    -0.559096  \n",
       "4  0.502292  0.219422  0.215153      0       1.175805    -0.558973  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert the above created new scaled variables to the dataset as index 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.908399</td>\n",
       "      <td>-0.559218</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.288512</td>\n",
       "      <td>-0.559218</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.891862</td>\n",
       "      <td>-0.559096</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.340078</td>\n",
       "      <td>-0.559096</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.175805</td>\n",
       "      <td>-0.558973</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       2.908399    -0.559218 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.288512    -0.559218  1.191857  0.266151  0.166480  0.448154   \n",
       "2       7.891862    -0.559096 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       2.340078    -0.559096 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       1.175805    -0.558973 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = fraud['scaled_amount']\n",
    "scaled_time = fraud['scaled_time']\n",
    "\n",
    "fraud.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "fraud.insert(0, 'scaled_amount', scaled_amount)\n",
    "fraud.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing X and y using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.908399</td>\n",
       "      <td>-0.559218</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.288512</td>\n",
       "      <td>-0.559218</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.891862</td>\n",
       "      <td>-0.559096</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.340078</td>\n",
       "      <td>-0.559096</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.175805</td>\n",
       "      <td>-0.558973</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       2.908399    -0.559218 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.288512    -0.559218  1.191857  0.266151  0.166480  0.448154   \n",
       "2       7.891862    -0.559096 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       2.340078    -0.559096 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       1.175805    -0.558973 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V19       V20       V21  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.403993  0.251412 -0.018307   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.145783 -0.069083 -0.225775   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ... -2.261857  0.524980  0.247998   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -1.232622 -0.208038 -0.108300   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = fraud.loc[:,fraud.columns != 'Class']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = fraud.loc[:,fraud.columns == 'Class']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Spliting X and y into train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the shape of X and y of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 30)\n",
      "(7500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the shape of X and y of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 30)\n",
      "(2500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to make 2 models one without any parameter specification and in other we will specify some parameter values. Then in later sections we will compare the performance of these models using various model evaluation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Random Forest Classifier using scikit learn with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1 = RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Random Forest Classifier using scikit learn with:\n",
    "- criterion='entropy'\n",
    "- n_estimators = 15\n",
    "- random_state = 0\n",
    "- max_depth = 3\n",
    "- min_samples_split=5\n",
    "- min_samples_leaf=4\n",
    "- max_leaf_nodes=5\n",
    "- n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=15,\n",
    "                                random_state = 0,\n",
    "                                max_depth=3,\n",
    "                                min_samples_split=5,\n",
    "                                min_samples_leaf=4,\n",
    "                                max_leaf_nodes=5,\n",
    "                                n_jobs=-1,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model on X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=5,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=-1,\n",
       "                       oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = pd.DataFrame()\n",
    "prediction1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = pd.DataFrame()\n",
    "prediction2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section501></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model evaluation using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test data with model 1 is: 0.9984\n",
      "Accuracy score for test data with model 2 is: 0.9988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score for test data with model 1 is:',accuracy_score(y_test, prediction1))\n",
    "print('Accuracy score for test data with model 2 is:',accuracy_score(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Accuracy score__ of both the models are approximately __equal__.<br/>\n",
    "Therefore, to comapre between the models we need to use some other evaluation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section502></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model evaluation using confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for test data with model 2 is:\n",
      " [[2491    2]\n",
      " [   2    5]]\n",
      "Confusion matrix for test data with model 2 is:\n",
      " [[2493    0]\n",
      " [   3    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion matrix for test data with model 2 is:\\n',confusion_matrix(y_test, prediction1))\n",
    "print('Confusion matrix for test data with model 2 is:\\n',confusion_matrix(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing confusion matrix for the two models: \n",
    "- No. of __False negative__ cases are __more__ in model2\n",
    "- No. of __False positive__ cases are __less__ in model2\n",
    "\n",
    "Calculating Recall and precision score for a clearer picture of the scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section503></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Model evaluation using precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for test data using model1 is: 0.7142857142857143\n",
      "Precision score for test data using model2 is: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision1 = precision_score(y_test,prediction1)\n",
    "print('Precision score for test data using model1 is:', precision1)\n",
    "precision2 = precision_score(y_test,prediction2)\n",
    "print('Precision score for test data using model2 is:', precision2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section504></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Model evaluation using recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for test data using model1 is: 0.7142857142857143\n",
      "Recall score for test data using model2 is: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print('Recall score for test data using model1 is:',recall_score(y_test,prediction1))   \n",
    "print('Recall score for test data using model2 is:',recall_score(y_test,prediction2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall score of model1 is higher, so __model1 is preferable__ from recall point of view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section505></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Model evaluation using F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score for test data using model1 is: 0.7142857142857143\n",
      "F1_score for test data using model2 is: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1_score for test data using model1 is:',f1_score(y_test, prediction1))\n",
    "print('F1_score for test data using model2 is:',f1_score(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1_score for both the models are approximately __same__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section506a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Model evaluation using ROC_AUC curve\n",
    "- For model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 4.01123145e-04\n",
      " 8.02246290e-04 1.20336943e-03 1.20336943e-03 2.40673887e-03\n",
      " 5.21460088e-03 1.00000000e+00]\n",
      "\n",
      "\n",
      "[0.         0.42857143 0.57142857 0.57142857 0.71428571 0.71428571\n",
      " 0.85714286 0.85714286 0.85714286 1.        ]\n",
      "\n",
      "\n",
      "[2.  1.  0.9 0.7 0.6 0.5 0.4 0.2 0.1 0. ]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "probs = model1.predict_proba(X_test)\n",
    "print(probs)\n",
    "print(\"\\n\")\n",
    "preds = probs[:,1]\n",
    "print(preds)\n",
    "print(\"\\n\")\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "print(fpr)\n",
    "print(\"\\n\")\n",
    "print(tpr)\n",
    "print(\"\\n\")\n",
    "print(threshold)\n",
    "print(\"\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "probs = model2.predict_proba(X_test)\n",
    "pred = probs[:,1]\n",
    "fpr1, tpr1, threshold = metrics.roc_curve(y_test, pred)\n",
    "roc_auc = metrics.auc(fpr1, tpr1)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr1, tpr1, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the ROC-AUC curve for both the models, observing that there is __no significant difference__ between the two plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = section5.7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Choosing better model using recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have compared the performance of the two models using various model evaluation techinques.<br/>\n",
    "Our objective is to __minimize False Negative__ as missing a lot of fradulent transactions is worse than predicting “fraud” on non fraudulent transactions, <br/>as more enquiry will be done on them in further steps. Therefore, among recall & precision scores, we will give more importance to __recall score__.\n",
    "\n",
    "- Recall score for model1 is: __0.71__\n",
    "- Recall score for model2 is: __0.57__\n",
    "\n",
    "As recall score of model1 is __better__ than that of model2, hence for predicting fradulent transaction __model1 is preferable.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
